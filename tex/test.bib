@inproceedings{Swirski2013,
abstract = {Spatio-temporal irradiance variations are created by some structured light setups. They also occur naturally underwater, where they are termed flicker. Underwater, visibility is also affected by water scattering. Methods for overcoming or exploiting flicker or scatter exist, when the imaging geometry is static or quasi-static. This work removes the need for quasi-static scene-object geometry under flickering illumination. A scene is observed from a free moving platform that carries standard frame-rate stereo cameras. The 3D scene structure is illumination invariant. Thus, as a reference for motion estimation, we use projections of stereoscopic range maps, rather than object radiance. Consequently, each object point can be tracked and then filtered in time, yielding deflickered videos. Moreover, since objects are viewed from different distances as the stereo rig moves, scattering effects on the images are modulated. This modulation, the recovered camera poses, 3D structure and de-flickered images yield inversion of scattering and recovery of the water attenuation coefficient. Thus, coupled difficult problems are solved in a single framework. This is demonstrated in underwater field experiments and in a lab.},
author = {Swirski, Yohay and Schechner, Yoav Y.},
booktitle = {2013 IEEE International Conference on Computational Photography, ICCP 2013},
doi = {10.1109/ICCPhot.2013.6528294},
file = {:Users/user/Library/Application Support/Mendeley Desktop/Downloaded/Swirski, Schechner - 2013 - 3Deflicker from motion.pdf:pdf},
isbn = {9781467364645},
mendeley-groups = {Vision},
title = {{3Deflicker from motion}},
year = {2013}
}

@article{Carlevaris-Bianco2010,
abstract = {As light is transmitted from subject to observer it is absorbed and scattered by the medium it passes through. In mediums with large suspended particles, such as fog or turbid water, the effect of scattering can drastically decrease the quality of images. In this paper we present an algorithm for removing the effects of light scattering, referred to as dehazing, in underwater images. Our key contribution is to propose a simple, yet effective, prior that exploits the strong difference in attenuation between the three image color channels in water to estimate the depth of the scene. We then use this estimate to reduce the spatially varying effect of haze in the image. Our method works with a single image and does not require any specialized hardware or prior knowledge of the scene. As a by-product of the dehazing process, an up-to-scale depth map of the scene is produced. We present results over multiple real underwater images and over a controlled test set where the target distance and true colors are known.},
author = {Carlevaris-Bianco, Nicholas and Mohan, Anush and Eustice, Ryan M.},
doi = {10.1109/OCEANS.2010.5664428},
file = {:Users/user/Desktop/Papers/05664428 (1).pdf:pdf},
isbn = {9781424443321},
journal = {MTS/IEEE Seattle, OCEANS 2010},
keywords = {defogging,dehazing,image enhancement,image processing,image restoration,underwater},
mendeley-groups = {Vision},
title = {{Initial results in underwater single image dehazing}},
year = {2010}
}

@online{Blueview,
  author = {Teledyne Blueview},
  title = {Blueview Imaging Sonar},
  url = {http://www.blueview.com/products/2d-imaging-sonar/p450-series/},
}

@article{Williams2004,
abstract = { This paper presents results of the application of the simultaneous localisation and mapping algorithm to data collected by an unmanned underwater vehicle operating on the Great Barrier Reef in Australia. By fusing information from the vehicle's on-board sonar and vision systems, it is possible to use the highly textured reef to provide estimates of the vehicle motion as well as to generate models of the gross structure of the underlying reefs. Terrain-aided navigation promises to revolutionise the ability of marine systems to track underwater bodies in many applications. This work represents a crucial step in the development of underwater technologies capable of long-term, reliable deployment. Results of the application of this technique to the tracking of the vehicle position are shown.},
author = {Williams, S. and Mahon, I.},
doi = {10.1109/ROBOT.2004.1308080},
file = {:Users/user/Desktop/Papers/reef.pdf:pdf},
isbn = {0-7803-8232-3},
issn = {1050-4729},
journal = {IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004},
mendeley-groups = {Sonar},
title = {{Simultaneous localisation and mapping on the Great Barrier Reef}},
volume = {2},
year = {2004}
}

@article{Xu2012,
author = {Xu, Guo H and Wu, Li Y and Yu, Kun and Yang, Cheng and Yang, Lin},
file = {:Users/user/Desktop/Papers/calib/ISOPE-I-12-258.pdf:pdf},
keywords = {forward-looking sonar,identification and positioning,proximate sensor,single camera,ultrasonic},
mendeley-groups = {Sonar/Calib Papers},
pages = {467--471},
title = {{Multi-target Detection of Underwater Vehicle Based on Multi-sensor Data Fusion}},
volume = {4},
year = {2012}
}

@article{Spears,
author = {Spears, Anthony and Howard, Ayanna M and West, Michael and Collins, Thomas},
file = {:Users/user/Desktop/Papers/calib/Fuse Sonar+Video (FOV Angle).pdf:pdf},
keywords = {SIFT,calibration,cross-calibration,georgia tech research institute,histogram-,histogram-of-gradients,michael west,of-gradients,sensor-fusion,sift,sonar,thomas collins,under-ice,underwater},
mendeley-groups = {Sonar/Calib Papers},
title = {{Acoustic Sonar and Video Sensor Fusion for Landmark Detection in an Under-Ice Environment}}
}

@article{Krout2011,
author = {Krout, D.W. and Okopal, G. and Hanusa, E.},
file = {:Users/user/Library/Application Support/Mendeley Desktop/Downloaded/Krout, Okopal, Hanusa - 2011 - Video data and sonar data real world data fusion example.pdf:pdf},
isbn = {9780982443828},
journal = {Information Fusion (FUSION), 2011 Proceedings of the 14th International Conference on},
keywords = {imaging sonar,tracking,video},
mendeley-groups = {Sonar/Calib Papers},
pages = {1 -- 5},
title = {{Video data and sonar data : real world data fusion example}},
year = {2011}
}

@article{Clark2007,
abstract = {Two contrasting approaches for tracking multiple targets in multi-beam forward-looking sonar images are considered. The first approach is based on assigning a Kalman filter to each target and managing the measurements with gating and a measurement-to-track data association technique. The second approach uses the recently developed particle implementation of the multiple-target probability hypothesis density (PHD) filter and a target state estimate-to-track data association technique. The two approaches are implemented and compared on both simulated sonar and real forward-looking sonar data obtained from an autonomous underwater vehicle (AUV) and demonstrate that the PHD filter with data association compares well with traditional approaches for multiple target tracking},
author = {Clark, Daniel and Ruiz, Ioseba Tena and Petillot, Yvan and Bell, Judith},
doi = {10.1109/TAES.2007.357143},
file = {:Users/user/Desktop/Papers/04194781.pdf:pdf},
isbn = {0018-9251},
issn = {00189251},
journal = {IEEE Transactions on Aerospace and Electronic Systems},
mendeley-groups = {Sonar},
pages = {409--415},
title = {{Particle PHD filter multiple target tracking in sonar image}},
volume = {43},
year = {2007}
}

@article{Miller2010,
abstract = {This paper considers the vehicle navigation problem for an autonomous underwater vehicle (AUV) with six degrees of freedom. We approach this problem using an error state formulation of the Kalman filter. Integration of the vehicle's high-rate inertial measurement unit's (IMU's) accelerometers and gyros allow time propagation while other sensors provide measurement corrections. The low-rate aiding sensors include a Doppler velocity log (DVL), an acoustic long baseline (LBL) system that provides round-trip travel times from known locations, a pressure sensor for aiding depth, and an attitude sensor. Measurements correct the filter independently as they arrive, and as such, the filter is not dependent on the arrival of any particular measurement. We propose novel tightly coupled techniques for the incorporation of the LBL and DVL measurements. In particular, the LBL correction properly accounts for the error state throughout the measurement cycle via the state transition matrix. Alternate tightly coupled approaches ignore the error state, utilizing only the navigation state to account for the physical latencies in the measurement cycle. These approaches account for neither the uncertainty of vehicle trajectory between interrogation and reply, nor the error state at interrogation. The navigation system also estimates critical sensor calibration parameters to improve performance. The result is a robust navigation system. Simulation and experimental results are provided.},
author = {Miller, Paul a. and Farrell, Jay a. and Zhao, Yuanyuan and Djapic, Vladimir},
doi = {10.1109/JOE.2010.2052691},
file = {:Users/user/Desktop/Papers/05546885.pdf:pdf},
issn = {03649059},
journal = {IEEE Journal of Oceanic Engineering},
keywords = {Acoustic long baseline (LBL) aiding,Doppler aiding,Kalman filter,inertial navigation,underwater vehicles},
mendeley-groups = {Sonar},
number = {3},
pages = {663--678},
title = {{Autonomous underwater vehicle navigation}},
volume = {35},
year = {2010}
}

@article{Negahdaripour2009,
abstract = {Utilization of an acoustic camera for range measurements is a key advantage for 3-D shape recovery of underwater targets by opti-acoustic stereo imaging, where the associated epipolar geometry of optical and acoustic image correspondences can be described in terms of conic sections. In this paper, we propose methods for system calibration and 3-D scene reconstruction by maximum likelihood estimation from noisy image measurements. The recursive 3-D reconstruction method utilized as initial condition a closed-form solution that integrates the advantages of two other closed-form solutions, referred to as the range and azimuth solutions. Synthetic data tests are given to provide insight into the merits of the new target imaging and 3-D reconstruction paradigm, while experiments with real data confirm the findings based on computer simulations, and demonstrate the merits of this novel 3-D reconstruction paradigm.},
author = {Negahdaripour, Shahriar and Sekkati, Hicham and Pirsiavash, Hamed},
doi = {10.1109/TIP.2009.2013081},
file = {:Users/user/Desktop/Papers/calib/04815402.pdf:pdf},
isbn = {1424411807},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {3-D reconstruction,Sensor integration,Stereovision,Underwater sonar imaging},
mendeley-groups = {Sonar/Calib Papers},
number = {6},
pages = {1203--1214},
pmid = {19380272},
title = {{Opti-acoustic stereo imaging: On system calibration and 3-D target reconstruction}},
volume = {18},
year = {2009}
}

@article{Negahdaripour2010,
abstract = {Range measurements offer a key advantage in deploying a sonar and an optical camera as a multi-modal stereo imaging system for 3-D object shape recovery in underwater. Establishing the relative pose of these cameras by a priori calibration enables exploiting the opti-acoustic epipolar geometry, and confine the complex multi-modal correspondence problem to a 1-D search. By imaging points on a known planar grid with distinct visual and acoustic reflectance properties, we previously proposed an iterative optimization scheme for opti-acoustic stereo calibration, requiring a search in 6+3N space based on N opti-acoustic stereo pairs of the grid at different orientations. In this paper, we present a new calibration method, where most of the computations are carried out in closed form, with a final search in 3-D space. Although extendable to make use of data from several views, the current implementation applies to only one view of the target grid. Thus, the results can be less accurate than the solution from the iterative method, for sonar cameras with a small field of view. We assess the performance of this method and discuss its merits based on experimental results with synthetic and real data.},
author = {Negahdaripour, S.},
doi = {10.1109/OCEANS.2010.5664563},
file = {:Users/user/Desktop/Papers/calib/05664563.pdf:pdf},
isbn = {9781424443321},
journal = {MTS/IEEE Seattle, OCEANS 2010},
keywords = {2-D FS sonar imaging,Optical and Sonar Imaging,Stereo Calibration},
mendeley-groups = {Sonar/Calib Papers},
pages = {1--7},
title = {{A new method for calibration of an opti-acoustic stereo imaging system}},
year = {2010}
}

@article{marquardt:1963,
  abstract = {Most algorithms for the least-squares estimation of non-linear parameters
	have centered about either of two approaches. On the one hand, the
	model may be expanded as a Taylor series and corrections to the several
	parameters calculated at each iteration on the assumption of local
	linearity. On the other hand, various modifications of the method
	of steepest-descent have been used. Both methods not infrequently
	run aground, the Taylor series method because of divergence of the
	successive iterates, the steepest-descent (or gradient) methods because
	of agonizingly slow convergence after the first few iterations. In
	this paper a maximum neighborhood method is developed which, in effect,
	performs an optimum interpolation between the Taylor series method
	and the gradient method, the interpolation being based upon the maximum
	neighborhood in which the truncated Taylor series gives an adequate
	representation of the nonlinear model. The results are extended to
	the problem of solving a set of nonlinear algebraic equations.},
  added-at = {2012-09-01T13:08:21.000+0200},
  author = {Marquardt, Donald W.},
  biburl = {http://www.bibsonomy.org/bibtex/28da575d91ad08f7cfdf1178206b9d326/nilsma},
  doi = {10.1137/0111030},
  interhash = {ffab42c8e029f1cb83353a60ae734987},
  intrahash = {8da575d91ad08f7cfdf1178206b9d326},
  journal = {SIAM Journal on Applied Mathematics},
  keywords = {inversion mathematics},
  number = 2,
  pages = {431--441},
  publisher = {SIAM},
  timestamp = {2012-09-01T13:09:12.000+0200},
  title = {An algorithm for least-squares estimation of nonlinear parameters},
  url = {http://dx.doi.org/10.1137/0111030},
  volume = 11,
  year = 1963
}

@online{BBAUV,
  author = {BBAUV},
  title = {BBAUV 2.5},
  url = {http://www.bbauv.com/vehicles/bumblebee-2-0/},
}

@InCollection{handbook-of-robotics,
  author	= "Alberto Broggi AND Alexander Zelinsky AND Michel Parent
		  AND Charles E. Thorpe",
  title		= "{Intelligent Vehicles}",
  booktitle	= "Springer Handbook of Robotics",
  month		= may,
  year		= 2008,
  editor	= "Bruno Siciliano AND Oussama Khatib",
  publisher	= "Springer Berlin Heidelberg",
  pages		= "1175--1198",
  chapter	= "51",
  eprint	= "doi:10.1007/978-3-540-30301-5-52",
  note		= "ISBN 978-3-540-23957-4"
}

@article{Coiras2009,
author = {Coiras, E and Groen, J},
file = {:Users/user/Desktop/Papers/calib/6014.pdf:pdf},
isbn = {9783902613486},
journal = {Advances in sonar technology. IN-TECH},
mendeley-groups = {Sonar/Modelling},
number = {February},
pages = {1--15},
title = {{Simulation and 3d reconstruction of sidelooking sonar images}},
url = {http://www.intechopen.com/source/pdfs/6014/InTech-Simulation\_and\_3d\_reconstruction\_of\_side\_looking\_sonar\_images.pdf},
year = {2009}
}

@article{Creuze2005,
abstract = {Navigation of autonomous underwater vehicles (A.U.V.) in very shallow waters implies acoustic detection. In single beam sonar systems, sound emitted by ultrasonic transducers is diffracted and secondary lobes appear. Considering the sea bottom's backscattering properties, secondary lobes can be used to work out the three-dimensional equation of the plane that represents the seabed. In this paper, we first consider characteristics of electro-acoustic transducers with rectangular aperture and study the resulting acoustic diffraction. Then, we explain how to choose the best dimensions of the transducer and the related best orientation. Moreover, we introduce a method aiming to extract the seabed 3D equation from the received acoustic echo. Thus single beam sonar systems can be used for bottom tracking purposes. We present the results of our simulations and our experimental device},
author = {Creuze, V. and Jouvencel, B. and Baccou, P.},
doi = {10.1109/ICAR.2005.1507389},
file = {:Users/user/Library/Application Support/Mendeley Desktop/Downloaded/Creuze, Jouvencel, Baccou - 2005 - 3D-bottom tracking based on acoustic diffraction for autonomous underwater vehicles.pdf:pdf},
isbn = {0-7803-9178-0},
journal = {ICAR '05. Proceedings., 12th International Conference on Advanced Robotics, 2005.},
mendeley-groups = {Sonar/Calib Papers},
pages = {3--8},
title = {{3D-bottom tracking based on acoustic diffraction for autonomous underwater vehicles}},
year = {2005}
}

@article{Sturm1999,
abstract = {We present a general algorithm for plane-based calibration that
can deal with arbitrary numbers of views and calibration planes. The
algorithm can simultaneously calibrate different views from a camera
with variable intrinsic parameters and it is easy to incorporate known
values of intrinsic parameters. For some minimal cases, we describe all
singularities, naming the parameters that can not be estimated.
Experimental results of our method are shown that exhibit the
singularities while revealing good performance in non-singular
conditions. Several applications of plane-based 3D geometry inference
are discussed as well},
author = {Sturm, P.F. and Maybank, S.J.},
doi = {10.1109/CVPR.1999.786974},
file = {:Users/user/Desktop/Papers/calib/sturm99.pdf:pdf},
isbn = {0-7695-0149-4},
issn = {1063-6919},
journal = {Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)},
mendeley-groups = {Sonar/Calib Papers},
number = {c},
title = {{On plane-based camera calibration: A general algorithm,
singularities, applications}},
volume = {1},
year = {1999}
}

@article{Trieb2005,
author = {J. Torstensson and M. Trieb},
journal = {Division of Automatic Control Department of Electrical Engineering Link ̈oping University, Sweden},
title = {{Particle Filtering for Track Before Detect Applications}},
year = {2005}
}

@article{Fox1999,
abstract = {This paper presents a new algorithm for mobile robot lo- calization, called Monte Carlo Localization (MCL). MCL is a version of Markov localization, a family of probabilis- tic approaches that have recently been applied with great practical success. However, previous approaches were ei- ther computationally cumbersome (such as grid-based ap- proaches that represent the state space by high-resolution 3D grids), or had to resort to extremely coarse-grained res- olutions. Our approach is computationally efficient while retaining the ability to represent (almost) arbitrary dis- tributions. MCL applies sampling-based methods for ap- proximating probability distributions, in a way that places computation “ where needed.” The number of samples is adapted on-line, thereby invoking large sample sets only when necessary. Empirical results illustrate thatMCLyields improved accuracy while requiring an order of magnitude less computationwhen compared to previous approaches. It is also much easier to implement.},
author = {Fox, Dieter and Burgard, Wolfram and Dellaert, Frank and Thrun, Sebastian},
doi = {10.1.1.2.342},
file = {:Users/user/Desktop/fox.aaai99.pdf:pdf},
journal = {16th National Conference on Artificial Intelligence (AAAI99)},
number = {Handschin 1970},
pages = {343--349},
title = {{Monte Carlo Localization: Efficient Position Estimation for Mobile Robots Dieter Fox, Wolfram Burgard}},
year = {1999}
}

@ARTICLE{4804062, 
author={Deveau, D.M. and Lyons, A.P.}, 
journal={Oceanic Engineering, IEEE Journal of}, 
title={Fluid-Filled Passive Sonar Calibration Spheres: Design, Modeling, and Measurement}, 
year={2009}, 
volume={34}, 
number={1}, 
pages={93-100}, 
keywords={acoustic wave scattering;calibration;sonar target recognition;underwater sound;acoustic projector systems;acoustic scattering strength;fluid-filled passive sonar calibration spheres;focusing effects;frequency 5 kHz to 120 kHz;mechanical support systems;size 0.1524 m to 0.4953 m;thin-walled spheres;underwater sonar targets;Acoustic measurements;Acoustic scattering;Acoustic testing;Calibration;Energy resolution;Frequency;Shape;Sonar measurements;System testing;Underwater acoustics;Acoustic target strength;fluid-filled sphere;modeling;scattering}, 
doi={10.1109/JOE.2008.2010755}, 
ISSN={0364-9059}, 
month={Jan},}

@ARTICLE{dubois-1999-cse, 
author={Dubois, Paul F.}, 
journal={Computing Science and Engineering}, 
title={Extending Python with Fortran}, 
year={1999}, 
}

@article{Quigley2009,
abstract = {This paper gives an overview of ROS, an open- source robot operating system. ROS is not an operating system in the traditional sense of process management and scheduling; rather, it provides a structured communications layer above the host operating systems of a heterogenous compute cluster. In this paper, we discuss how ROS relates to existing robot software frameworks, and briefly overview some of the available application software which uses ROS},
author = {Quigley, Morgan and Conley, Ken and Gerkey, Brian and FAust, Josh and Foote, Tully and Leibs, Jeremy and Berger, Eric and Wheeler, Rob and Mg, Andrew},
doi = {http://www.willowgarage.com/papers/ros-open-source-robot-operating-system},
file = {:Users/user/Desktop/icraoss09-ROS.pdf:pdf},
isbn = {0165-022X (Print)$\backslash$r0165-022X (Linking)},
issn = {0165022X},
journal = {Icra},
number = {Figure 1},
pages = {5},
pmid = {8844323},
title = {{ROS: an open-source Robot Operating System}},
url = {http://pub1.willowgarage.com/~konolige/cs225B/docs/quigley-icra2009-ros.pdf},
volume = {3},
year = {2009}
}

@ARTICLE{opencv_library, 
author={Bradski, G.}, 
journal={Dr. Dobb's Journal of Software Tools}, 
title={OpenCV Library}, 
year={2000}, 
}

@article{Kim2001,
abstract = {Identification concerning different types of radar targets can be achieved by using various radar signatures, such as one-dimensional (1-D) range profiles, 2-D radar images, and 1-D or 2-D scattering centres on a target. To solve the target identification problem, the authors utilise 1-D scattering centres, which correspond to the highest peaks in the 1-D range profile. The proposed approach obtains scale and translational-invariant features based on the central moments from the distribution of the 1-D scattering centres on the target; these 1-D scattering centres can be extracted from various techniques such as inverse fast Fourier transform (IFFT), fast root-multiple signal classification (fast root-MUSIC), total least squares-Prony (TLS-Prony), generalised eigenvalues utilising signal subspace eigenvectors (GEESE), and the matrix-pencil (MP) algorithm. The information redundancy contained in these features, as well as their dimensions, are further reduced via the Karhunen–Loeve transform, followed by adequate scaling of the computed central moments. The resulting small dimensional and redundancy-free feature vectors are classified using the Bayes classifier. Finally, this new strategy for radar-target identification is demonstrated with data measured in the compact range facility, and the above five different techniques for 1-D scattering centre extraction are compared and investigated in the context of target identification},
author = {Kim, Kt and Seo, Dk and Kim, Ht},
doi = {10.1049/ip-rsn},
file = {:Users/user/Desktop/Papers/calib/01500263.pdf:pdf},
issn = {<null>},
journal = {IEE Proceedings-Radar, Sonar and Navigation},
mendeley-groups = {Sonar/Calib Papers},
number = {4},
pages = {285--296},
title = {{Radar target identification using one-dimensional scattering centres}},
url = {http://digital-library.theiet.org/content/journals/10.1049/ip-rsn\_20010473},
volume = {152},
year = {2001}
}

@article{Knauer2006,
abstract = {Principle component analysis (PCA) is commonly used to compute a bounding box of a point set in Rd. In this paper we give bounds on the approximation factor of PCA bounding boxes of convex polygons in R2 (lower and upper bounds) and convex polyhedra in R3 (lower bound).},
author = {Knauer, Christian and Kriegel, Klaus},
file = {:Users/user/Desktop/10.1.1.127.5985.pdf:pdf},
journal = {2nd European Workshop on Computational Geometry},
pages = {193--196},
title = {{On the Bounding Boxes Obtained by Principal Component Analysis}},
year = {2006}
}

@online{PFDemo,
  author = {Eiji Ota},
  title = {Simple Particle Filter Demo},
  url = {http://www.mathworks.com/matlabcentral/fileexchange/33666-simple-particle-filter-demo},
}
